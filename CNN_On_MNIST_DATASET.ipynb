{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNUfy9mvnaXHgOOlvR99B9C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aftabgazali/CNN_On_MNIST_DATASET/blob/main/CNN_On_MNIST_DATASET.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing the Libraries"
      ],
      "metadata": {
        "id": "AlbxX74FRJ7q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bMgCbLsnRGYM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up the Device Agnostic Code"
      ],
      "metadata": {
        "id": "cSLg5c5aRYPt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "id": "ozGbWlEoRbNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing the Data, Applying transforms and converting to Tensors"
      ],
      "metadata": {
        "id": "0R5zlLMPRg7D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor()])"
      ],
      "metadata": {
        "id": "vDstBOWMR8wu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = datasets.MNIST(root=\"data\", train= True, transform= transform, target_transform= None, download= True)\n",
        "test_data = datasets.MNIST(root=\"data\", train= False, transform= transform, target_transform= None, download= True)"
      ],
      "metadata": {
        "id": "wpcjgeGaRf0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data), len(test_data)"
      ],
      "metadata": {
        "id": "pQunyKHpSItV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualizing the Data"
      ],
      "metadata": {
        "id": "3vzdUfZ1SM-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image, label = train_data[0]"
      ],
      "metadata": {
        "id": "eZ0S8tWCSPi6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## So the dataset is already in a grayscale form"
      ],
      "metadata": {
        "id": "GRq3kcyGSgEL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image.shape, label"
      ],
      "metadata": {
        "id": "KijXQSuvSS1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_data.classes\n",
        "class_names"
      ],
      "metadata": {
        "id": "Yga9uLR4S-Bx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "figure = plt.figure(figsize=(10,7))\n",
        "rows,cols = 4,4\n",
        "for i in range(1, rows*cols+1):\n",
        "  random_index = torch.randint(0, len(train_data), size=[1]).item()\n",
        "  image, label = train_data[random_index]\n",
        "  figure.add_subplot(rows,cols,i)\n",
        "  plt.imshow(image.squeeze())\n",
        "  plt.title(class_names[label])\n",
        "  plt.axis(False)"
      ],
      "metadata": {
        "id": "SkhU-CptSmUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing the Data into Batches"
      ],
      "metadata": {
        "id": "sW-6_weiTP5g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "train_data_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_data_loader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=False)"
      ],
      "metadata": {
        "id": "Juelqo3ITSxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data_loader), len(test_data_loader)"
      ],
      "metadata": {
        "id": "nfugwihHTusX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building a Simple Linear Model"
      ],
      "metadata": {
        "id": "5adGwfxdTy4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MNISTV0(nn.Module):\n",
        "  def __init__(self, input_shape:int, output_shape:int, hidden_units:int):\n",
        "    super().__init__()\n",
        "    self.layer_stacked = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=input_shape, out_features=hidden_units),\n",
        "        nn.Linear(in_features=hidden_units, out_features=output_shape)\n",
        "    )\n",
        "\n",
        "  # Forward Pass\n",
        "  def forward(self, x:torch.Tensor):\n",
        "    return self.layer_stacked(x)\n",
        "\n",
        "# Creating the Instance of the baseline model\n",
        "model_v0 = MNISTV0(input_shape=28*28, output_shape=len(class_names), hidden_units=4).to(device)"
      ],
      "metadata": {
        "id": "RyEQA-EZTyYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_v0.state_dict"
      ],
      "metadata": {
        "id": "d66foTYwUpoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Loss & Optimizer Functions"
      ],
      "metadata": {
        "id": "OQUGAHCRUvdP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_loss = nn.CrossEntropyLoss()\n",
        "model_optimizer = torch.optim.Adam(params = model_v0.parameters())"
      ],
      "metadata": {
        "id": "RiU1tfUGUuZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building the Accuracy Function"
      ],
      "metadata": {
        "id": "hNYv9271U-Ie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_accuracy(y_true, y_pred):\n",
        "  acc = torch.eq(y_true,y_pred).sum().item()\n",
        "  return (acc/len(y_true))*100"
      ],
      "metadata": {
        "id": "dMlRI3tSVCq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building the Training & Testing Step"
      ],
      "metadata": {
        "id": "BqF18fhPVQr4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "def train_step(model: torch.nn.Module, no_of_epochs:int, data_loader: torch.utils.data, model_loss:torch.nn.Module, model_acc, model_optimizer:torch.optim, device: torch.device = device):\n",
        "  \"\"\"\n",
        "    Training Step for Model\n",
        "  \"\"\"\n",
        "  for epoch in tqdm(range(no_of_epochs)):\n",
        "    print(f\"Epochs {epoch} ------------------------- \")\n",
        "    # Training Mode:\n",
        "    model.train()\n",
        "    train_loss, train_acc = 0,0\n",
        "    for batch, (X,y) in enumerate(data_loader):\n",
        "      X,y = X.to(device), y.to(device)\n",
        "      # Forward Pass\n",
        "      y_logits = model(X)\n",
        "\n",
        "      # Calculate the Loss\n",
        "      loss = model_loss(y_logits, y)\n",
        "      train_loss += loss\n",
        "\n",
        "      # Caculate the training acc\n",
        "      train_acc += model_acc(y, y_logits.argmax(dim=1))\n",
        "      # Optimizer zero grad\n",
        "      model_optimizer.zero_grad()\n",
        "\n",
        "      # Loss Backward\n",
        "      loss.backward()\n",
        "\n",
        "      # Optmizier step\n",
        "      model_optimizer.step()\n",
        "\n",
        "      if batch % 400 == 0:\n",
        "        print(f\"Looked Through {batch * len(X)} / {len(train_data_loader.dataset)} samples\")\n",
        "\n",
        "    # Update the training loss & training accuracy\n",
        "    train_loss /= len(data_loader)\n",
        "    train_acc /= len(data_loader)\n",
        "    print(f\"Training Loss {train_loss} Training Accuracy {train_acc}\")"
      ],
      "metadata": {
        "id": "vofrZQ2MVG5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_step(model_v0, 3, train_data_loader, model_loss, model_accuracy, model_optimizer)"
      ],
      "metadata": {
        "id": "bhqyHx2PX11F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "def test_step(model: torch.nn.Module, data_loader: torch.utils.data, model_loss:torch.nn.Module, model_acc,device: torch.device = device):\n",
        "  \"\"\"\n",
        "    Testing Step for the Model\n",
        "  \"\"\"\n",
        "  # Testing Mode:\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    test_loss, test_acc = 0,0\n",
        "    for X_test,y_test in tqdm(data_loader):\n",
        "        # Forward Pass\n",
        "        X_test, y_test = X_test.to(device), y_test.to(device)\n",
        "        y_logits = model(X_test)\n",
        "\n",
        "        # Calculate the Loss\n",
        "        test_loss += model_loss(y_logits, y_test)\n",
        "\n",
        "        # Caculate the training acc\n",
        "        test_acc += model_acc(y_test, y_logits.argmax(dim=1))\n",
        "      # Update the training loss & training accuracy\n",
        "    test_loss /= len(data_loader)\n",
        "    test_acc /= len(data_loader)\n",
        "    print(f\"Training Loss {test_loss:.2f} Training Accuracy {test_acc:.2f}\")"
      ],
      "metadata": {
        "id": "dsUwmTAUYf7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_step(model_v0,test_data_loader, model_loss, model_accuracy)"
      ],
      "metadata": {
        "id": "Hk2Z-9ffZGaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building Eval Model Method"
      ],
      "metadata": {
        "id": "DGH0yNGQir44"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_model(model:torch.nn.Module, data_loader: torch.utils.data, model_loss:torch.nn.Module, model_acc,device: torch.device = device):\n",
        "  # Testing Mode:\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    test_loss, test_acc = 0,0\n",
        "    for X_test,y_test in tqdm(data_loader):\n",
        "        X_test,y_test = X_test.to(device),y_test.to(device)\n",
        "        # Forward Pass\n",
        "        y_logits = model(X_test)\n",
        "\n",
        "        # Calculate the Loss\n",
        "        test_loss += model_loss(y_logits, y_test)\n",
        "\n",
        "        # Caculate the training acc\n",
        "        test_acc += model_acc(y_test, y_logits.argmax(dim=1))\n",
        "      # Update the training loss & training accuracy\n",
        "    test_loss /= len(data_loader)\n",
        "    test_acc /= len(data_loader)\n",
        "    return {'model':model.__class__.__name__,'Loss':(test_loss*100).item(),'Accuracy':test_acc}"
      ],
      "metadata": {
        "id": "majK6ecAirct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_v0_results= eval_model(model_v0,test_data_loader, model_loss, model_accuracy)"
      ],
      "metadata": {
        "id": "mgf8O23rjFXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building the Non-Linear Model"
      ],
      "metadata": {
        "id": "ARdv-6ZYZ6v4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MNISTV1(nn.Module):\n",
        "  def __init__(self, input_shape:int, output_shape:int, hidden_units:int):\n",
        "    super().__init__()\n",
        "    self.layer_stacked = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=input_shape, out_features=hidden_units),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(in_features=hidden_units, out_features=output_shape),\n",
        "    )\n",
        "  # Forward Pass\n",
        "  def forward(self, x:torch.Tensor):\n",
        "    return self.layer_stacked(x)\n",
        "\n",
        "# Creating the Instance of the baseline model\n",
        "model_v1 = MNISTV1(input_shape=28*28, output_shape=len(class_names), hidden_units=4).to(device)"
      ],
      "metadata": {
        "id": "xo3e_i7EZ9gh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Loss & Optimizer functions"
      ],
      "metadata": {
        "id": "tKaMetpHaURW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_loss = nn.CrossEntropyLoss()\n",
        "model_optimizer = torch.optim.Adam(params = model_v1.parameters())"
      ],
      "metadata": {
        "id": "45D8xKjAaXdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building Training & Testing Step"
      ],
      "metadata": {
        "id": "JGgy5QNiacBV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_step(model_v1, 3, train_data_loader, model_loss, model_accuracy, model_optimizer)"
      ],
      "metadata": {
        "id": "ZgtLGHejamki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_step(model_v1,test_data_loader, model_loss, model_accuracy)"
      ],
      "metadata": {
        "id": "V1YccnbGavKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building the CNN Model"
      ],
      "metadata": {
        "id": "eNN2ANQJa95Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MNISTV2(nn.Module):\n",
        "  def __init__(self, input_shape:int, output_shape:int, hidden_units:int):\n",
        "    super().__init__()\n",
        "    self.conv_2d_layer_1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=input_shape, out_channels=hidden_units, kernel_size=2,stride=1,padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units*4, kernel_size=2,stride=1,padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2)\n",
        "    )\n",
        "    self.classifier_layer = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=hidden_units*4*15*15,out_features=output_shape)\n",
        "    )\n",
        "  # Forward Pass\n",
        "  def forward(self, x:torch.Tensor):\n",
        "    x = self.conv_2d_layer_1(x)\n",
        "    #print(f\"Shape of X {x.shape}\")\n",
        "    return self.classifier_layer(x)\n",
        "\n",
        "# Creating the Instance of the baseline model\n",
        "model_v2 = MNISTV2(input_shape=1, output_shape=len(class_names), hidden_units=16).to(device)"
      ],
      "metadata": {
        "id": "x-MRYktBbAKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_image = torch.randn(size=(1,28,28))\n",
        "model_v2(test_image.unsqueeze(0).to(device))"
      ],
      "metadata": {
        "id": "Fb3WVb_BcPro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_loss = nn.CrossEntropyLoss()\n",
        "model_optimizer = torch.optim.Adam(params = model_v2.parameters())"
      ],
      "metadata": {
        "id": "CDl0tQoqdueI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_step(model_v2, 5, train_data_loader, model_loss, model_accuracy, model_optimizer)"
      ],
      "metadata": {
        "id": "Ss-dTrgXcXiN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_step(model_v2,test_data_loader, model_loss, model_accuracy)"
      ],
      "metadata": {
        "id": "PHa5BCPjdtZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Achieved an Impressive Accuracy of 99.57%"
      ],
      "metadata": {
        "id": "Pba_MPXMii1g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparing Model Results"
      ],
      "metadata": {
        "id": "KLsObS0Djqwa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_v0_results= eval_model(model_v0,test_data_loader, model_loss, model_accuracy)\n",
        "model_v1_results= eval_model(model_v1,test_data_loader, model_loss, model_accuracy)\n",
        "model_v2_results= eval_model(model_v2,test_data_loader, model_loss, model_accuracy)"
      ],
      "metadata": {
        "id": "QIVrYnsNjshc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_results_df = pd.DataFrame([model_v0_results,model_v1_results,model_v2_results])\n",
        "model_results_df"
      ],
      "metadata": {
        "id": "glILq4Myjz_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_results_df.set_index('model')['Accuracy'].plot(kind='barh', color='g')\n",
        "plt.xlabel('Accuracy %')\n",
        "plt.ylabel('Models')"
      ],
      "metadata": {
        "id": "j03cNudCkfpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Making Predictions"
      ],
      "metadata": {
        "id": "4ER7gIuxeCeg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_images_per_batch, test_labels_per_batch = next(iter(test_data_loader))"
      ],
      "metadata": {
        "id": "0ABvFnh4eUM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "figure = plt.figure(figsize=(16,8))\n",
        "rows, cols = 4,4\n",
        "\n",
        "for i in range(1, rows*cols+1):\n",
        "  random_index = torch.randint(0, len(test_images_per_batch), size=[1]).item()\n",
        "  image, label = test_images_per_batch[random_index], test_labels_per_batch[random_index]\n",
        "  y_logits = model_v2(image.unsqueeze(0).to(device))\n",
        "  test_prediction_label = y_logits.argmax(dim=1)\n",
        "  figure.add_subplot(rows,cols,i)\n",
        "  title = f\"Predicted {class_names[test_prediction_label]} | Actual {class_names[label]}\"\n",
        "  plt.imshow(image.squeeze())\n",
        "  if class_names[test_prediction_label] == class_names[label]:\n",
        "    plt.title(title,color=\"g\")\n",
        "  else:\n",
        "    plt.title(title, color=\"r\")\n",
        "  plt.axis(False)"
      ],
      "metadata": {
        "id": "RVN4XO68eErU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Making Prediction using Real Images"
      ],
      "metadata": {
        "id": "BW1H3vQf1f7P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image"
      ],
      "metadata": {
        "id": "ldQHxICYzxhv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize((28, 28)),\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Load the image from an outside source\n",
        "image = Image.open('test_3.png')\n",
        "\n",
        "# Preprocess the image with blur and add a batch dimension\n",
        "input_tensor = preprocess(image).unsqueeze(0)"
      ],
      "metadata": {
        "id": "9dJSjjE1zqUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(input_tensor.squeeze())"
      ],
      "metadata": {
        "id": "72YB64GJ1kRo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_logitss = model_v2(input_tensor.to(device))\n",
        "y_logitss"
      ],
      "metadata": {
        "id": "mmaFfLqEz50P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = y_logitss.argmax(dim=1)\n",
        "plt.imshow(input_tensor.squeeze())\n",
        "plt.title(f\"Predicted Label {class_names[pred]} | Actual Label is 3\")\n",
        "plt.axis(False)"
      ],
      "metadata": {
        "id": "QwqyWile0DCT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}